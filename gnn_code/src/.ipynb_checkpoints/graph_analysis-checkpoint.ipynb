{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f085cb68-0536-46f5-a272-e079c6011b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection.reddit_user_dataset import RedditUserDataset\n",
    "from data_collection.reddit_user_dataset import convert_timeframes_to_model_input\n",
    "from classification.feature_computing import Embedder\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "import random\n",
    "import gzip\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from utils.file_sort import path_sort\n",
    "from argparse import ArgumentParser\n",
    "import argparse\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from random import randrange\n",
    "import json\n",
    "from utils.utils import *\n",
    "import torch\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b188561f-bcb3-4a55-ad2a-4bc3c791f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_path='../data/reddit_dataset/reddit_corpus_unbalanced_filtered.gzip' \n",
    "base_dataset = RedditUserDataset.load_from_file(base_dataset_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff8b6a1-2b43-4d55-b720-4d97afe119f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_frame_dir = '../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source'\n",
    "\n",
    "source_graph_descriptor = pkl.load(\n",
    "    gzip.open(os.path.join(source_frame_dir, 'source_graph_descriptor.data'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f703ea-292c-4b27-b794-d1bcfc49b396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_0.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_1.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_2.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_3.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_4.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_5.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_6.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_7.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_8.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_9.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_10.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_11.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_12.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_13.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_14.pkl\n",
      "../data/reddit_dataset/linguistic/cosine/avg/usr2vec_delta30_new/source/source_graph_15.pkl\n"
     ]
    }
   ],
   "source": [
    "doc_embedding_file_path= source_graph_descriptor['embedding_file_path']\n",
    "embed_type= source_graph_descriptor['embed_type']\n",
    "merge_liwc=source_graph_descriptor['merge_liwc']\n",
    "dim=source_graph_descriptor['dim']\n",
    "embedder = Embedder([doc_embedding_file_path], embed_type, dim)\n",
    "threshold = 0.8\n",
    "timeframed_dataset = []\n",
    "doc_amount_avgs = []\n",
    "\n",
    "for graph in path_sort(\n",
    "        [join(source_frame_dir, f) for f in listdir(source_frame_dir) if isfile(join(source_frame_dir, f))]):\n",
    "    if \"source_graph_descriptor.data\" in graph:\n",
    "        continue\n",
    "    print(graph)\n",
    "    timeframe_ds = RedditUserDataset.load_from_instance_file(graph)\n",
    "    timeframe_ds.shorten_similarity_triplet_list(threshold)\n",
    "    timeframed_dataset.append(timeframe_ds)\n",
    "    doc_sum = 0\n",
    "    users = 0\n",
    "    for index, row in RedditUserDataset.load_from_instance_file(graph).data_frame.iterrows():\n",
    "        users += 1\n",
    "        doc_sum += row['num_docs']\n",
    "    doc_amount_avgs.append(doc_sum / users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65a1148c-e1d1-45f0-bbd8-c4ab08358528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNumbers:\n",
    "    def __init__(self, edges, nodes, fns, rns, m2m, m2r, r2r):\n",
    "        self.edges = edges\n",
    "        self.nodes = nodes\n",
    "        self.fns = fns\n",
    "        self.rns = rns\n",
    "        self.m2m = m2m\n",
    "        self.m2r = m2r \n",
    "        self.r2r = r2r\n",
    "        \n",
    "    def print_attr(self):\n",
    "        print(self.__dict__)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a2ef1bd-7aa1-435d-86d6-ba449a26a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:58<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8\n",
    "numbers_per_month = []\n",
    "\n",
    "for tf_d in tqdm(timeframed_dataset):\n",
    "    df = tf_d.data_frame\n",
    "    n_edges = 0\n",
    "    nodes = set()\n",
    "    n_fns = set()\n",
    "    n_rns = set()\n",
    "    n_m2m = 0\n",
    "    n_m2r = 0\n",
    "    n_r2r = 0\n",
    "    \n",
    "    for similarities in tf_d.similarity_triplets:\n",
    "        user1, user2, sim = similarities\n",
    "        if sim > threshold:\n",
    "            n_edges += 1\n",
    "            nodes.add(user1)\n",
    "            nodes.add(user2)\n",
    "            \n",
    "            label1 = df[df['user_id'] == user1]['fake_news_spreader'].values[0]\n",
    "            label2 = df[df['user_id'] == user2]['fake_news_spreader'].values[0]\n",
    "            \n",
    "            if label1 == 1:\n",
    "                n_fns.add(user1)\n",
    "            else:\n",
    "                n_rns.add(user1)\n",
    "                \n",
    "            if label2 == 1:\n",
    "                n_fns.add(user2)\n",
    "            else:\n",
    "                n_rns.add(user2)\n",
    "            \n",
    "            if label1 != label2:\n",
    "                n_m2r += 1\n",
    "            elif label1 == 1 and label2 == 1:\n",
    "                n_m2m += 1\n",
    "            elif label1 == 0 and label2 == 0:\n",
    "                n_r2r += 1\n",
    "            else:\n",
    "                print(label1, label2)\n",
    "                raise Exception(\"Wrong\")\n",
    "            \n",
    "    numbers_per_month.append(GraphNumbers(n_edges, len(nodes), len(n_fns), len(n_rns), n_m2m, n_m2r, n_r2r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4907b77-8043-412b-8058-9c1bef2d0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/per_month_numbers.json', 'w') as f:\n",
    "    json.dump([g.__dict__ for g in numbers_per_month], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c841b1-a36b-4927-b8f3-d423cc4876f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
